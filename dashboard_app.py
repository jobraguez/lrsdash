#!/usr/bin/env python3
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import subprocess, sys
import unidecode
from dateutil import parser
import re
import os
from fpdf import FPDF
import tempfile

# --- CONFIGURA√á√ÉO GERAL ---
st.set_page_config(page_title="Dashboard Anima√ß√£o 2D", layout="wide")

# --- AUTENTICA√á√ÉO SIMPLES ---
CREDENTIALS = {
    "admin": {"password": "admin123", "view": "admin"},
    "learn": {"password": "learn123", "view": "learn"}
}

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
    st.session_state.user_role = None

if not st.session_state.logged_in:
    st.title("üîí Login Necess√°rio")
    user = st.text_input("üë§ Utilizador")
    pwd = st.text_input("üîë Password", type="password")
    login_btn = st.button("Entrar")

    if login_btn:
        if user and user in CREDENTIALS and CREDENTIALS[user]["password"] == pwd:
            st.session_state.logged_in = True
            st.session_state.user_role = CREDENTIALS[user]["view"]

        else:
            st.error("Utilizador ou palavra-passe incorretos.")

    st.stop()

    
# ‚îÄ‚îÄ‚îÄ 1. Constantes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
CSV_FILE = "statements_clean.csv"
DIAG_CSV       = 'diagnostica_clean.csv'
FINAL_CSV      = 'final_clean.csv'
SATISF_CSV     = 'satisfacao_clean.csv'
DIAG_RAW = "a2d12_avaliacao_diagnostica_notas.csv"
FINAL_RAW = "a2d12_avalia√ß√£o_final-notas.csv"
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

# --- BOT√ÉO PARA ATUALIZAR ---
from streamlit.runtime.scriptrunner import RerunException, RerunData
if st.button("üîÑ Atualizar dados"):
    # chama o export.py com o mesmo interpretador Python
    subprocess.run([sys.executable, "export.py"], check=True)
    # for√ßa o Streamlit a reiniciar o script
    raise RerunException(RerunData())
    
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
@st.cache_data
# --- FUN√á√ÉO: EXTRAIR M√âDIAS DE PERGUNTAS DO CSV BRUTO ---
def extract_avg_scores(path):
    
    # 1) Leitura com v√≠rgula como separador
    df_raw = pd.read_csv(path, sep=',', encoding='utf8', dtype=str)

    # 2) Procura a linha 'M√©dia' na primeira coluna
    first_col = df_raw.columns[0]
    mask = df_raw[first_col].str.strip().eq("M√©dia")
    if not mask.any():
        raise ValueError(f"M√©dia row not found in {path}")

    avg_row = df_raw[mask].iloc[0]

    # 3) Seleciona apenas colunas de pergunta, por exemplo 'P. 1 /0,77'
    #    usar regex para pegar colunas que come√ßam por 'P.'
    q_cols = [c for c in df_raw.columns if re.match(r"^\s*P\.\s*\d+", c)]
    if not q_cols:
        raise ValueError(f"No question columns found in {path}")

    # 4) Extrai valores, substitui v√≠rgula por ponto e converte em float
    avg_scores = {}
    for col in q_cols:
        raw = avg_row[col]
        if pd.isna(raw):
            continue
        # mant√©m apenas a parte num√©rica antes de qualquer espa√ßo
        # ou "/" para tirar o "/0,77" que acompanha no header
        val_str = re.split(r"[ /]", raw.strip())[0]
        val_str = val_str.replace(",", ".")
        try:
            avg_scores[col] = float(val_str)
        except ValueError:
            # ignora se n√£o der para converter
            continue

    # 5) Retorna Series com √≠ndice "P. 1", "P. 2", ...
    #    retirando o resto do texto da coluna
    clean_index = [re.match(r"P\.\s*(\d+)", c).group(0) for c in avg_scores.keys()]
    return pd.Series(list(avg_scores.values()), index=clean_index)

# --- no seu fluxo principal, troque a chamada anterior por:
try:
    diag_avgs  = extract_avg_scores(DIAG_RAW)
    final_avgs = extract_avg_scores(FINAL_RAW)
    # monte um DataFrame para exibir lado a lado
    df_evol = pd.DataFrame({
        "Diagn√≥stica": diag_avgs,
        "Final":      final_avgs
    }).dropna(how="all")  # tira perguntas que n√£o existem em nenhum
    df_evol["Diferen√ßa"] = (df_evol["Final"] - df_evol["Diagn√≥stica"]).round(1)

    #st.subheader("üìà Evolu√ß√£o M√©dia por Pergunta")
    #st.dataframe(df_evol, use_container_width=True)
    #st.line_chart(df_evol[["Diagn√≥stica","Final"]])

except Exception as e:
    st.warning(f"N√£o foi poss√≠vel extrair as m√©dias dos CSVs brutos: {e}")

# --- FUN√á√ÉO: CARREGAMENTO DE DADOS ---
def load_data():
    df = pd.read_csv(CSV_FILE)
    df.columns = df.columns.map(str)
    # 2.1 Timestamp ‚Üí datetime[ns, UTC]
    df["timestamp"] = (
        df["timestamp"]
        .astype(str)  # garante object
        .apply(lambda s: parser.isoparse(s) if s and s.lower() != "nan" else pd.NaT)
        .dt.tz_convert("UTC")
    )
    # 2.2 Limpa m√≥dulo de espa√ßos/brancos invis√≠veis
    df["module"] = df["module"].astype(str).str.strip()
    # avalia√ß√µes
    df_diag = pd.read_csv(DIAG_CSV)
    df_final = pd.read_csv(FINAL_CSV)
    df_satis = pd.read_csv(SATISF_CSV)
    return df, df_diag, df_final, df_satis

# --- INICIALIZA OS DADOS ---
df, df_diag, df_final, df_satis = load_data()
# Lista de m√≥dulos realmente existentes (ordenada)
modules_list = sorted(df["module"].dropna().unique())
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
def load_satisfacao():
    df = pd.read_csv(SATISF_CSV, encoding="utf8")
    # 1) Concelhos: colunas que come√ßam por ‚ÄúQ05_Distrito‚Äù
    concelhos = [c for c in df.columns if c.startswith("Q05_Distrito")]
    # melt para apanhar o concelho com valor True/1
    df_conc = (
        df[["ID"] + concelhos]
        .melt(id_vars="ID", value_vars=concelhos,
              var_name="origem", value_name="flag")
        .query("flag == True or flag == 1")
    )
    df_conc["Distrito"] = df_conc["origem"].str.split("->").str[-1]
    # 2) Escolaridade: colunas que come√ßam por ‚ÄúQ07_N√≠vel‚Äù
    escolaridade = [c for c in df.columns if c.startswith("Q07_N√≠vel")]
    df_esc = (
        df[["ID"] + escolaridade]
        .melt(id_vars="ID", value_vars=escolaridade,
              var_name="origem", value_name="flag")
        .query("flag == True or flag == 1")
    )
    df_esc["Escolaridade"] = df_esc["origem"].str.split("->").str[-1]
    # 3) Nacionalidade diretamente
    df_nat = df[["ID", "Q06_Nacionalidade"]].rename(
        columns={"Q06_Nacionalidade": "Nacionalidade"}
    )
    # 4) Junta tudo
    df_demo = (
        df_nat
        .merge(df_conc[["ID", "Distrito"]], on="ID", how="left")
        .merge(df_esc[["ID", "Escolaridade"]], on="ID", how="left")
        .drop(columns="ID")
    )
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Normaliza√ß√£o de Nacionalidades ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 1) Lowercase e strip
    df_demo["Nacionalidade"] = (
        df_demo["Nacionalidade"]
        .astype(str)
        .str.lower()
        .str.strip()
    )

    # 2) Dicion√°rio de mapeamento das variantes para o termo can√≥nico
    mapping = {
        # Portuguesa
        "portugal": "Portuguesa",
        "portugual": "Portuguesa",
        "portuguesa": "Portuguesa",
        "potuguesa": "Portuguesa",
        "portugu√™s": "Portuguesa",
        "pt": "Portuguesa",
    }

    # 3) Aplica o mapeamento, valores n√£o inclu√≠dos ficam como 'Outro'
    df_demo["Nacionalidade"] = (
        df_demo["Nacionalidade"]
        .map(mapping)
        .fillna(df_demo["Nacionalidade"].str.title())  # t√≠tulo de variantes desconhecidas
    )
    return df_demo

 # --- Selector de vis√£o ---
    #    view = st.sidebar.radio(
    #    "üóÇÔ∏è Seleciona a Vis√£o",
    #    ["Vis√£o Admin", "Vis√£o Learn Stats"]
    #)

if st.session_state.user_role == "admin":
    st.session_state.view = "admin"
elif st.session_state.user_role == "learn":
    st.session_state.view = "learn"
else:
    st.stop()  # seguran√ßa extra
    
# ‚îÄ‚îÄ‚îÄ VIS√ÉO ADMINISTRATIVA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if st.session_state.view == "admin":
    st.title("üîß Vis√£o Admin")
    st.text("Dashboard de administra√ß√£o do curso Anima√ß√£o 2D")
    st.text("Este painel tem dados completos, para uma vis√£o de s√≠ntese e j√° com algumas conclus√µes, por favor aceda √† Vis√£o Learn Stats")

    # ‚îÄ‚îÄ‚îÄ M√âTRICAS GERAIS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.header("Vis√£o Geral")
    c1, c2, c3 = st.columns(3)
    c1.metric("Total Statements", len(df))
    c2.metric("Total M√≥dulos", df["module"].nunique())

    # Normaliza coluna module para filtragem
    df["module_norm"] = (
        df["module"]
        .astype(str)
        .fillna("")
        .apply(unidecode.unidecode)
        .str.lower()
        .str.strip()
    )
    df["verb_lc"] = df["verb"].str.lower()
    
    # Filtra utilizadores que submeteram o question√°rio de satisfa√ß√£o
    mask_satisf_submit = (
            (df["verb_lc"] == "submitted") &
            (df["module_norm"].str.contains("satisfacao", na=False))
    )

    # Conta utilizadores √∫nicos
    n_users_satisf = df[mask_satisf_submit]["user"].nunique()

    # Atualiza m√©trica com esse valor
    c3.metric("Total Utilizadores", n_users_satisf)

     # ‚îÄ‚îÄ‚îÄ STATEMENTS POR M√ìDULO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.subheader("üì¶ Statements por M√≥dulo")

    # Garante zero para m√≥dulos sem statements hoje
    mod_counts = df["module"].value_counts().reindex(modules_list, fill_value=0)

    # Tabela
    st.dataframe(
        mod_counts
        .rename_axis("M√≥dulo")
        .reset_index(name="Contagem")
    )

    # Gr√°fico de barras
    fig, ax = plt.subplots(figsize=(8,4))
    mod_counts.plot.bar(ax=ax)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.set_xlabel("M√≥dulo")
    ax.set_ylabel("N√∫mero de statements")
    plt.xticks(rotation=45, ha='right')
    st.pyplot(fig)
    plt.tight_layout()
   
    # ‚îÄ‚îÄ‚îÄ VERBOS POR M√ìDULO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.subheader("üî§ Verbos mais comuns")
    # 1) Pivot table: linhas = m√≥dulo, colunas = verbo, valores = contagem
    verb_counts = df["verb"].value_counts()
    st.dataframe(
        verb_counts
        .rename_axis("Verbo")
        .reset_index(name="Contagem")
    )
    st.bar_chart(verb_counts)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    # ‚îÄ‚îÄ‚îÄ X. Contagem de Verbos por M√≥dulo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.subheader("üìä Verbos por M√≥dulo")

    # 1) Pivot table: linhas = m√≥dulo, colunas = verbo, valores = contagem
    verbs_of_interest = ["completed","answered","progressed","interacted","attempted"]
    # normaliza tudo para lowercase para evitar duplicados
    df["verb_lc"] = df["verb"].str.lower()

    pivot = (
        df[df["verb_lc"].isin(verbs_of_interest)]
        .groupby(["module","verb_lc"])
        .size()
        .unstack(fill_value=0)
        .reindex(columns=verbs_of_interest, fill_value=0)
    )

    # 2) Exibe tabela
    st.dataframe(pivot.rename_axis("M√≥dulo").rename(columns=str.capitalize))

    # 3) Gr√°fico de barras empilhadas (opcional)
    fig2, ax2 = plt.subplots(figsize=(10, 5))
    pivot.plot(
        kind="bar",
        stacked=True,
        ax=ax2
    )
    ax2.set_xlabel("M√≥dulo")
    ax2.set_ylabel("Contagem de Statements")
    ax2.legend(title="Verbo", bbox_to_anchor=(1.02,1), loc="upper left")
    plt.xticks(rotation=45, ha="right")
    st.pyplot(fig2)

    # ‚îÄ‚îÄ‚îÄ 7. Evolu√ß√£o Di√°ria de Statements ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    st.subheader("üìÖ Evolu√ß√£o Di√°ria de Statements")

    # Garante que estamos usando DatetimeIndex
    df_daily = df.set_index("timestamp").resample("D").size()
    st.line_chart(df_daily)
    
    
    # ‚îÄ‚îÄ‚îÄ TENTATIVAS Por Pergunta ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.subheader("‚ùì Tentativas por Pergunta")
    st.text("Perguntas do m√≥dulo 1 ao 4 (perguntas dos conte√∫dos H5P). ")
    # filtra statements com verbo contendo 'attempt' e 'answer'
    df_attempts = df[df['verb'].str.lower().str.contains('attempt', na=False)]

    # conta tentativas e respondidas por activity
    attempts = df_attempts['activity'].value_counts()

    # mant√©m s√≥ perguntas que come√ßam por "Pergunta"
    mask = attempts.index.str.startswith("Pergunta")
    attempts = attempts[mask]

    # prepara DataFrame final
    df_q = pd.DataFrame({
        'Pergunta': attempts.index,
        'Tentativas': attempts.values,

    })
    if df_q.empty:
        st.info("N√£o h√° tentativas registadas em perguntas.")
    else:
        # ordena√ß√£o interativa
        sort_col = st.selectbox("Ordenar por:", ['Pergunta', 'Tentativas'], index=1)
        asc = st.checkbox("Ordem ascendente", value=False)
        df_q_sorted = df_q.sort_values(sort_col, ascending=asc)
        # exibe tabela completa
        # st.dataframe(df_q_sorted, use_container_width=True)
        # gr√°fico de barras agrupadas
        fig, ax = plt.subplots(figsize=(10, 5))
        x = range(len(df_q_sorted))
        ax.bar(x, df_q_sorted['Tentativas'], width=0.4, label='Tentativas')

        ax.set_xticks([i + 0.2 for i in x])
        ax.set_xticklabels(df_q_sorted['Pergunta'], rotation=45, ha='right')
        ax.set_xlabel("Pergunta")
        ax.set_ylabel("Contagem")
        ax.legend()
        plt.tight_layout()
        st.pyplot(fig)
    
    # ‚îÄ‚îÄ‚îÄ Avalia√ß√µes & Satisfa√ß√£o ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.header("üìä Avalia√ß√£o diagn√≥stica, Avalia√ß√£o final e Inqu√©rito de Satisfa√ß√£o")
    #st.text("Todas respostas")
    tabs = st.tabs(["Ava. Diagn√≥stica", "Ava. Final", "Inq. Satisfa√ß√£o"])
    df_diag.columns = [col.replace("id", "Tempo") if col.lower() == "id" else col for col in df_diag.columns]

    with tabs[0]:
        st.subheader("üìù Avalia√ß√£o Diagn√≥stica")
        st.dataframe(df_diag, use_container_width=True)
        # exemplo de gr√°fico de respostas por quest√£o
        if 'Pergunta' in df_diag.columns and 'Resposta' in df_diag.columns:
            q_counts = df_diag.groupby('Pergunta')['Resposta'].value_counts().unstack(fill_value=0)
            st.bar_chart(q_counts)

    with tabs[1]:
        st.subheader("üìù Avalia√ß√£o Final")
        st.dataframe(df_final, use_container_width=True)
        if 'Pergunta' in df_final.columns and 'Resposta' in df_final.columns:
            qf_counts = df_final.groupby('Pergunta')['Resposta'].value_counts().unstack(fill_value=0)
            st.bar_chart(qf_counts)

    with tabs[2]:
        st.subheader("üôÇ Satisfa√ß√£o do Curso")
        st.dataframe(df_satis, use_container_width=True)
        if 'Pergunta' in df_satis.columns and 'Resposta' in df_satis.columns:
            qs_counts = df_satis.groupby('Pergunta')['Resposta'].value_counts().unstack(fill_value=0)
            st.bar_chart(qs_counts)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# ‚îÄ‚îÄ‚îÄ  Vis√£o Learn Stats ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
else:
    st.title("üìä Vis√£o Learn Stats")
    st.text("Dashboard de estat√≠sticas do curso Anima√ß√£o 2D")
    st.text("Esta vis√£o tem dados j√° filtrados e com algumas conclus√µes. Esta vis√£o √© aconselhada a professores.")
    #  Carrega dados limpos
    df_sat = pd.read_csv("satisfacao_clean.csv", encoding="utf8")

    #  Caracteriza√ß√£o da Amostra
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    st.header("üìùCaracteriza√ß√£o da Amostra")

    df_satis = load_satisfacao()

    # st.subheader("üîπ Tabela de Caracteriza√ß√£o")
    # st.dataframe(df_satis)

    # Distribui√ß√µes
    col1, col2, col3 = st.columns(3)
    with col1:
        st.subheader("Distrito")
        st.bar_chart(df_satis["Distrito"].value_counts())
    with col2:
        st.subheader("Nacionalidade")
        st.bar_chart(df_satis["Nacionalidade"].value_counts())
    with col3:
        st.subheader("Escolaridade")
        st.bar_chart(df_satis["Escolaridade"].value_counts())

        # ‚îÄ‚îÄ‚îÄ Tempo Diagn√≥stica ‚Üí Satisfa√ß√£o por Utilizador ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    #st.subheader("‚è±Ô∏è Tempo")
    #st.text("Tempo m√©dio que os utilizadores levaram a concluir o curso. Foi contabilizado todo o tempo desde que iniciou at√© que finalizou. Assim mesmo que o utilizador fizesse log-off entre sess√µes, esse tempo foi contabilizado")
    # 1) Normaliza m√≥dulo
    df["module_norm"] = (
        df["module"]
        .fillna("")
        .astype(str)
        .apply(unidecode.unidecode)  # tira acentos
        .str.lower()
    )
    # 2) normaliza verbos
    df["verb_lc"] = df["verb"].str.lower()

    # 3) m√°scaras corretas
    start_mask = (
            (df["verb_lc"] == "viewed") &
            df["module_norm"].str.contains("diagnostica", na=False)
    )
    end_mask = (
            (df["verb_lc"].isin(["submitted", "answered"])) &
            df["module_norm"].str.contains("satisf", na=False)
    )

    # 5) agrupa e intersecta users
    starts = df[start_mask].groupby("user")["timestamp"].min()
    ends = df[end_mask].groupby("user")["timestamp"].max()
    common = starts.index.intersection(ends.index)

    if len(common) == 0:
        st.warning("‚ö†Ô∏è N√£o h√° utilizadores com ambos os eventos de in√≠cio e fim.")
    else:
        # 6) calcula dura√ß√µes em minutos
        durations = ((ends[common] - starts[common]).dt.total_seconds() / 60).round(1)
        avg = round(durations.mean(), 1)

        # 7) mostra resultados
        #st.metric("‚è≤Ô∏è Tempo M√©dio (min)", f"{avg}")
        dur_df = durations.reset_index()
        dur_df.columns = ["Utilizador", "Minutos"]
        # st.dataframe(dur_df, use_container_width=True)
        # st.bar_chart(dur_df.set_index("Utilizador")["Minutos"])

       # --- Evolu√ß√£o por Utilizador (Nota Global) ---
        def extract_overall_avg(path):
            # tenta ; e , como separadores
            for sep in (";", ","):
                try:
                    df = pd.read_csv(path, sep=sep, dtype=str, keep_default_na=False)
                except Exception:
                    continue
                if df.shape[1] > 1:
                    break
            else:
                raise ValueError(f"N√£o consegui ler {path} (sep. ';' ou ',').")

            # localiza a linha onde a primeira coluna √© 'M√©dia'
            col0 = df.columns[0]
            mask = df[col0].str.strip().eq("M√©dia")
            if not mask.any():
                raise ValueError(f"Linha 'M√©dia' n√£o encontrada em {path}")

            # captura toda a linha e procura o primeiro valor num√©rico
            row = df.loc[mask].iloc[0].tolist()
            for cell in row[1:]:
                if isinstance(cell, str) and re.match(r"^\s*\d+[,.]\d+\s*$", cell):
                    return float(cell.strip().replace(",", "."))
            raise ValueError(f"Nenhum valor num√©rico encontrado na linha 'M√©dia' de {path}")

        st.subheader("üìà Evolu√ß√£o dos utilizadores")
        st.text("A diferen√ßa entre a m√©dia das notas da avalia√ß√£o diagn√≥stica e final.")
        try:
            avg_diag = extract_overall_avg(DIAG_RAW)
            avg_final = extract_overall_avg(FINAL_RAW)
            diff = round(avg_final - avg_diag, 2)

            c1, c2, c3 = st.columns(3)
            c1.metric("M√©dia Diagn√≥stica", f"{avg_diag:.2f}")
            c2.metric("M√©dia Final", f"{avg_final:.2f}")
            c3.metric("Œî MELHORIA", f"{diff:.2f}")
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel extrair as m√©dias dos CSVs brutos: {e}")

    # --- Evolu√ß√£o por Pergunta (Diagn√≥stica vs Final) ---
        st.subheader("üìà Evolu√ß√£o por Pergunta")
        st.text("A diferen√ßa entre a m√©dia das notas da avalia√ß√£o diagn√≥stica e da avalia√ß√£o final por pergunta.")

        # caminhos para os CSVs brutos

        DIAG_RAW = "a2d12_avaliacao_diagnostica_notas.csv"
        FINAL_RAW = "a2d12_avalia√ß√£o_final-notas.csv"

        # Extract averages
        diag_avgs = extract_avg_scores(DIAG_RAW)
        final_avgs = extract_avg_scores(FINAL_RAW)

        # Build DataFrame
        df_evol = pd.DataFrame({
            "Diagn√≥stica": diag_avgs,
            "Final": final_avgs
        })

        # Calculate difference if you like
        df_evol["Diferen√ßa"] = (df_evol["Final"] - df_evol["Diagn√≥stica"]).round(2)

        # Display

        # st.dataframe(df_evol, use_container_width=True)
        st.line_chart(df_evol[["Diagn√≥stica", "Final"]])

    # --- Resultados por Pergunta
        # st.subheader("‚ùì Tentativas vs Respondidas por Pergunta (Global)")

        # filtra statements com verbo contendo 'attempt' e 'answer'
    df_attempts = df[df['verb'].str.lower().str.contains('attempt', na=False)]
    df_answered = df[df['verb'].str.lower().str.contains('answer', na=False)]

    # conta tentativas e respondidas por activity
    attempts = df_attempts['activity'].value_counts()
    answered = df_answered['activity'].value_counts()

    # mant√©m s√≥ perguntas que come√ßam por "Pergunta"
    mask = attempts.index.str.startswith("Pergunta")
    attempts = attempts[mask]
    answered = answered.reindex(attempts.index, fill_value=0)

    # prepara DataFrame final
    df_q = pd.DataFrame({
        'Pergunta': attempts.index,
        'Tentativas': attempts.values,
        'Respondida': answered.values
    })

    # --- Top-3 Global (M√≥dulos 1 a 4) ---
    st.subheader("üèÖ Top-3 Perguntas com melhores e piores classifica√ß√µes (M√≥dulos)")
    col_easy, col_hard = st.columns(2)

    # 3 mais f√°ceis: s√≥ Pergunta e Tentativas
    df_easy = df_q.nsmallest(3, 'Tentativas')[['Pergunta', 'Tentativas']].reset_index(drop=True)
    with col_easy:
        st.subheader("üü¢ Melhores Classifica√ß√µes")
        st.dataframe(df_easy)

    # 3 mais dif√≠ceis: s√≥ Pergunta e Tentativas
    df_hard = df_q.nlargest(3, 'Tentativas')[['Pergunta', 'Tentativas']].reset_index(drop=True)
    with col_hard:
        st.subheader("üî¥ Piores Classifica√ß√µes")
        st.dataframe(df_hard)

    # --- Top-3 F√°ceis e Dif√≠ceis (Avalia√ß√£o Final) ---
    st.subheader("üèÖ Top-3 Perguntas com melhores e piores classifica√ß√µes (Avalia√ß√£o Final)")
    # 1) L√™ o CSV bruto, autodetectando delimitador
    raw_final = pd.read_csv(
        "a2d12_avalia√ß√£o_final-notas.csv",
        sep=None,  # deixa o pandas adivinhar v√≠rgula vs ponto‚Äêe‚Äêv√≠rgula
        engine="python",
        dtype=str
    )
    # 2) Descobre qual √© a primeira coluna (normalmente "Apelido" ou similar)
    id_col = raw_final.columns[0]
    # 3) Procura a linha ‚ÄúM√©dia‚Äù nessa coluna
    mask_avg = (
        raw_final[id_col]
        .astype(str)
        .str.strip()
        .str.lower()
        .eq("m√©dia")
    )
    if not mask_avg.any():
        st.error(f"Linha 'M√©dia' n√£o encontrada na coluna {id_col!r}.")
    else:
        avg_row = raw_final.loc[mask_avg].iloc[0]
        # 4) Seleciona apenas as colunas de perguntas, ex: "P. 1 /0,77"
        q_cols = [c for c in raw_final.columns if re.match(r"^P\.\s*\d+", c)]
        if not q_cols:
            st.warning("Nenhuma coluna de pergunta (P. X) encontrada.")
        else:
            # 5) Extrai as m√©dias e converte "8,61" ‚Üí 8.61
            scores = (
                avg_row[q_cols]
                .str.replace(",", ".", regex=False)
                .astype(float)
            )
            # 6) Computa top‚Äê3 f√°ceis (maiores m√©dias) e top‚Äê3 dif√≠ceis (menores)
            df_easy = (
                scores.nlargest(3)
                .reset_index()
                .rename(columns={"index": "Pergunta", 18: "M√©dia"})
            )
            df_hard = (
                scores.nsmallest(3)
                .reset_index()
                .rename(columns={"index": "Pergunta", 18: "M√©dia"})
            )
            # 7) Exibe lado a lado
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("#### üü¢ 3 Melhores Classifica√ß√µes")
                st.dataframe(df_easy)
            with c2:
                st.markdown("#### üî¥ 3 Piores Classifica√ß√µes")
                st.dataframe(df_hard)


   # --- Resultados por Pergunta -Satisfa√ß√£o-  + Œ± Cronbach ---
    #  Resultados por Pergunta
    st.subheader("üìä Satisfa√ß√£o: Resultados por Pergunta")

    # Seleciona apenas colunas cujo nome comece por 'Q' seguido de d√≠gitos
    q_cols = [c for c in df_sat.columns
              if re.match(r"^Q0[1-3](_|$)", c, re.IGNORECASE)]

    if not q_cols:
        st.warning("Nenhuma coluna de pergunta Q01‚ÄìQ03 encontrada.")
    else:
        # Converte v√≠rgulas para ponto e for√ßa n√∫meros; erros vir√£o como NaN
        df_qnum = df_sat[q_cols].apply(
            lambda col: pd.to_numeric(
                col.astype(str).str.replace(",", ".", regex=False),
                errors="coerce"
            )
        )
        # Calcula m√©dia por pergunta, arredonda a 1 casa decimal
        mean_scores = df_qnum.mean().round(1)

        # Tabela interativa (orden√°vel)
        df_q = mean_scores.reset_index()
        df_q.columns = ["Pergunta", "M√©dia"]
        st.dataframe(df_q, use_container_width=True)
    # Gr√°fico de barras
        #st.bar_chart(mean_scores)
    # 3) Œ± de Cronbach
    # Remove linhas com NaN em qualquer uma das tr√™s
    df_items = df_qnum.dropna(how="any")
    if df_items.shape[0] < 2:
        st.warning("N√£o h√° dados suficientes para calcular o Œ± de Cronbach.")
    else:
        n_items = df_items.shape[1]
        item_vars = df_items.var(axis=0, ddof=1)
        total_var = df_items.sum(axis=1).var(ddof=1)
        cronbach_alpha = (n_items / (n_items - 1)) * (1 - item_vars.sum() / total_var)
        st.metric("üß™ Œ± de Cronbach (Inqu√©rito de Satisfa√ß√£o)", f"{cronbach_alpha:.2f}","Excelente!")

    # üñ®Ô∏è Bot√£o para gerar relat√≥rio
    if st.button("üìÑ Gerar Relat√≥rio em PDF"):
        with st.spinner("A gerar relat√≥rio..."):
            # Criar imagens tempor√°rias
            tmp_dir = tempfile.mkdtemp()

            # 1. Gr√°fico de Distrito
            distrito_fig, ax = plt.subplots()
            df_satis["Distrito"].value_counts().plot(kind="bar", ax=ax)
            ax.set_title("Distribui√ß√£o por Distrito")
            distrito_path = os.path.join(tmp_dir, "distrito.png")
            distrito_fig.savefig(distrito_path)
            plt.close(distrito_fig)
            # 1.b Nacionalidade
            nacionalidade_fig, ax = plt.subplots()
            df_satis["Nacionalidade"].value_counts().plot(kind="bar", ax=ax)
            ax.set_title("Distribui√ß√£o por Nacionalidade")
            nacionalidade_path = os.path.join(tmp_dir, "nacionalidade.png")
            nacionalidade_fig.savefig(nacionalidade_path)
            plt.close(nacionalidade_fig)
            # 1.c Escolaridade
            escolaridade_fig, ax = plt.subplots()
            df_satis["Escolaridade"].value_counts().plot(kind="bar", ax=ax)
            ax.set_title("Distribui√ß√£o por Escolaridade")
            escolaridade_path = os.path.join(tmp_dir, "escolaridade.png")
            escolaridade_fig.savefig(escolaridade_path)
            plt.close(escolaridade_fig)

            #tempo_medio_texto = f"Tempo m√©dio de conclus√£o do curso: {avg} minutos."
            top_easy_txt = "\n".join([f"{row['Pergunta']}: {row['M√©dia']:.2f}" for _, row in df_easy.iterrows()])
            top_hard_txt = "\n".join([f"{row['Pergunta']}: {row['M√©dia']:.2f}" for _, row in df_hard.iterrows()])

            # 2. Gr√°fico de evolu√ß√£o
            evol_fig, ax2 = plt.subplots()
            df_evol[["Diagn√≥stica", "Final"]].plot(ax=ax2)
            ax2.set_title("Evolu√ß√£o Diagn√≥stica vs Final")
            evol_path = os.path.join(tmp_dir, "evolucao.png")
            evol_fig.savefig(evol_path)
            plt.close(evol_fig)

            cronbach_txt = f"Alpha de Cronbach: {cronbach_alpha:.2f} (excelente consist√™ncia interna)."

            # 3. Criar PDF
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "Relat√≥rio - Vis√£o Learn Stats", ln=True)
            pdf.set_font("Arial", "", 12)
            pdf.multi_cell(0, 10, "Este relat√≥rio apresenta a caracteriza√ß√£o da amostra, "
                                  "a evolu√ß√£o dos resultados da avalia√ß√£o diagn√≥stica para a final "
                                  "e gr√°ficos com os principais indicadores.")

            # Inserir gr√°ficos
            # P√°gina 1 ‚Äì Caracteriza√ß√£o da amostra
            pdf.add_page()
            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 10, "Caracteriza√ß√£o da Amostra", ln=True)
            pdf.image(distrito_path, w=100)
            pdf.ln(5)
            pdf.image(nacionalidade_path, w=100)
            pdf.ln(5)
            pdf.image(escolaridade_path, w=100)

            # P√°gina 2 ‚Äì Tempo e Evolu√ß√£o
            pdf.add_page()
            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 10, "Tempo e Evolu√ß√£o", ln=True)
            pdf.set_font("Arial", "", 12)
            #pdf.multi_cell(0, 10, tempo_medio_texto)
            pdf.ln(5)
            pdf.image(evol_path, w=180)

            # P√°gina 3 ‚Äì Top-3 Perguntas e Cronbach
            pdf.add_page()
            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 10, "Top-3 Perguntas", ln=True)

            pdf.set_font("Arial", "B", 12)
            pdf.cell(0, 10, "Melhor Classifica√ß√£o", ln=True)
            pdf.set_font("Arial", "", 12)
            pdf.multi_cell(0, 10, top_easy_txt)

            pdf.ln(5)
            pdf.set_font("Arial", "B", 12)
            pdf.cell(0, 10, "Pior Classifica√ß√£o", ln=True)
            pdf.set_font("Arial", "", 12)
            pdf.multi_cell(0, 10, top_hard_txt)

            pdf.ln(5)
            pdf.set_font("Arial", "B", 12)
            pdf.cell(0, 10, "Consist√™ncia Interna", ln=True)
            pdf.set_font("Arial", "", 12)
            pdf.multi_cell(0, 10, cronbach_txt)

            # Guardar PDF
            pdf_path = os.path.join(tmp_dir, "relatorio_visao_learn.pdf")
            pdf.output(pdf_path)

            # Mostrar bot√£o de download
            with open(pdf_path, "rb") as f:
                st.download_button("‚¨áÔ∏è Baixar Relat√≥rio PDF", f, file_name="relatorio_learn.pdf")
